---
title: Cognitive Planning with LLMs
sidebar_position: 2
---

# Cognitive Planning with LLMs

## Learning Objectives

By the end of this chapter, you will be able to:
- Understand LLM-based cognitive planning for robotic actions
- Implement prompt engineering techniques for action sequence generation
- Validate and execute action plans safely
- Integrate cognitive planning with ROS 2 execution

## Prerequisites

- Intermediate robotics knowledge
- Python programming skills
- Basic understanding of ROS 2
- Familiarity with LLMs and prompt engineering

**Estimated Reading Time**: 45 minutes

## Introduction

Cognitive planning represents the intelligence layer in the Vision-Language-Action (VLA) framework, where large language models (LLMs) bridge the gap between natural language understanding and robotic action execution. This chapter explores how LLMs can generate complex action sequences from natural language commands, incorporating reasoning, planning, and safety validation.

Cognitive planning in robotics involves several key components:
- Natural language understanding and parsing
- Task decomposition and sequencing
- Action validation and safety checking
- Context-aware planning and adaptation

## Common Terminology and Concepts

Throughout this module, we'll use specific terminology related to Vision-Language-Action systems:

- **Cognitive Plan**: Sequence of robotic actions generated by LLM based on natural language understanding
- **LLM (Large Language Model)**: Advanced AI model capable of understanding and generating human language
- **Prompt Engineering**: Crafting effective prompts to guide LLM behavior for specific tasks
- **Action Sequence**: Ordered list of ROS 2 actions that accomplish a complex task
- **Task Decomposition**: Breaking down complex commands into simpler, executable actions
- **Chain-of-Thought**: Step-by-step reasoning approach for complex planning
- **Safety Validation**: Process of ensuring planned actions are safe and feasible
- **Context Window**: Limited memory of the LLM that affects planning complexity
- **Plan Dependencies**: Order relationships between actions in a sequence
- **Environmental Context**: Information about the robot's surroundings and capabilities

## LLM Planning Concepts

LLM-based cognitive planning for robotics involves transforming high-level natural language commands into detailed, executable action sequences. The process includes:

1. **Command Understanding**: Interpreting the user's intent from natural language
2. **Task Analysis**: Breaking down complex tasks into manageable subtasks
3. **Environmental Reasoning**: Considering the current state and constraints
4. **Action Sequencing**: Ordering actions in a logical and executable manner
5. **Safety Validation**: Ensuring the plan is safe and feasible
6. **Execution Monitoring**: Tracking plan progress and adapting as needed

### Prompt Engineering Techniques

Effective prompt engineering is crucial for generating reliable action sequences from LLMs:

#### Structured Prompt Format

```
You are a cognitive planning system for a humanoid robot. Your role is to generate detailed action sequences from natural language commands.

Context:
- Robot capabilities: navigation, manipulation, perception
- Current location: starting position
- Environment: known map with object locations

Command: [natural language command]

Please generate a detailed action sequence that includes:
1. Task breakdown with subtasks
2. Required actions with parameters
3. Safety considerations
4. Expected outcomes

Format your response as:
- Task: [main task description]
- Subtasks: [list of subtasks in order]
- Actions: [specific ROS 2 actions with parameters]
- Safety: [potential safety concerns]
- Expected: [expected outcome]
```

#### Example Implementation

```python
import openai
import json
import rospy
from std_msgs.msg import String
from geometry_msgs.msg import Pose
from typing import List, Dict, Any

class CognitivePlanningNode:
    def __init__(self):
        rospy.init_node('cognitive_planning')

        # Configuration for LLM API
        self.api_key = rospy.get_param('~openai_api_key', '')
        openai.api_key = self.api_key

        # Publishers for different action types
        self.navigation_pub = rospy.Publisher('/move_base/goal', Pose, queue_size=10)
        self.manipulation_pub = rospy.Publisher('/manipulation_actions', String, queue_size=10)
        self.perception_pub = rospy.Publisher('/perception_requests', String, queue_size=10)

        # Current robot state (in real implementation, this would come from TF or state topic)
        self.current_pose = Pose()
        self.environment_map = {}

    def generate_plan(self, natural_language_command: str) -> Dict[str, Any]:
        """
        Generate a cognitive plan from natural language command using LLM
        """
        prompt = self.create_planning_prompt(natural_language_command)

        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # Lower temperature for more consistent planning
                max_tokens=1000
            )

            plan_text = response.choices[0].message.content
            return self.parse_plan_response(plan_text)

        except Exception as e:
            rospy.logerr(f"Error generating plan: {str(e)}")
            return self.get_fallback_plan(natural_language_command)

    def create_planning_prompt(self, command: str) -> str:
        """
        Create a structured prompt for cognitive planning
        """
        return f"""
        You are a cognitive planning system for a humanoid robot. Your role is to generate detailed action sequences from natural language commands.

        Context:
        - Robot capabilities: navigation, manipulation, perception
        - Current location: (0, 0, 0) facing North
        - Environment: known map with object locations

        Natural Language Command: {command}

        Please generate a detailed action sequence that includes:
        1. Task breakdown with subtasks
        2. Required actions with parameters
        3. Safety considerations
        4. Expected outcomes

        Format your response as JSON:
        {{
            "task": "main task description",
            "subtasks": [
                {{"description": "subtask description", "action_type": "navigation|manipulation|perception", "parameters": {{"key": "value"}}}}
            ],
            "safety_considerations": ["consideration1", "consideration2"],
            "estimated_duration": "in seconds"
        }}
        """

    def get_system_prompt(self) -> str:
        """
        System prompt to guide the LLM's behavior
        """
        return """
        You are an expert cognitive planning system for humanoid robotics. Your role is to interpret natural language commands and generate safe, executable action sequences for a robot.

        Guidelines:
        1. Always prioritize safety in your planning
        2. Break complex tasks into simple, executable steps
        3. Consider environmental constraints and robot capabilities
        4. Include navigation, manipulation, and perception as needed
        5. Provide specific parameters for each action
        6. Recognize when a command is unsafe or impossible
        """

    def parse_plan_response(self, response_text: str) -> Dict[str, Any]:
        """
        Parse the LLM response and extract the plan
        """
        try:
            # Try to extract JSON from the response
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1

            if start_idx != -1 and end_idx != 0:
                json_str = response_text[start_idx:end_idx]
                plan = json.loads(json_str)

                # Validate the plan structure
                if 'subtasks' not in plan:
                    plan['subtasks'] = []

                return plan
            else:
                # If no JSON found, return a simple fallback plan
                return {
                    "task": "Unparsed task",
                    "subtasks": [],
                    "safety_considerations": ["Could not parse LLM response"],
                    "estimated_duration": 0
                }
        except json.JSONDecodeError:
            rospy.logwarn("Could not parse LLM response as JSON")
            return {
                "task": "Error parsing response",
                "subtasks": [],
                "safety_considerations": ["LLM response format error"],
                "estimated_duration": 0
            }

    def get_fallback_plan(self, command: str) -> Dict[str, Any]:
        """
        Generate a fallback plan when LLM fails
        """
        # Simple keyword-based fallback for common commands
        command_lower = command.lower()

        if "go to" in command_lower or "navigate to" in command_lower:
            return {
                "task": f"Navigate to location in command: {command}",
                "subtasks": [],
                "safety_considerations": ["Use safe navigation parameters"],
                "estimated_duration": 60
            }
        elif "pick up" in command_lower or "grasp" in command_lower:
            return {
                "task": f"Pick up object in command: {command}",
                "subtasks": [],
                "safety_considerations": ["Check object size and weight"],
                "estimated_duration": 120
            }
        else:
            return {
                "task": f"Unknown command: {command}",
                "subtasks": [],
                "safety_considerations": ["Cannot process command safely"],
                "estimated_duration": 0
            }

    def validate_plan(self, plan: Dict[str, Any]) -> bool:
        """
        Validate the plan for safety and feasibility
        """
        # Check if plan has required structure
        if not isinstance(plan, dict) or 'subtasks' not in plan:
            rospy.logerr("Plan missing required structure")
            return False

        # Check for potential safety issues
        for subtask in plan['subtasks']:
            if not self.validate_subtask(subtask):
                return False

        # Additional validation checks can be added here
        return True

    def validate_subtask(self, subtask: Dict[str, Any]) -> bool:
        """
        Validate individual subtask for safety and feasibility
        """
        if 'action_type' not in subtask:
            rospy.logerr(f"Subtask missing action type: {subtask}")
            return False

        action_type = subtask['action_type']

        if action_type not in ['navigation', 'manipulation', 'perception']:
            rospy.logerr(f"Unknown action type: {action_type}")
            return False

        # Additional validation based on action type
        if action_type == 'navigation':
            # Validate navigation parameters
            params = subtask.get('parameters', {})
            if 'target_pose' not in params:
                rospy.logerr(f"Navigation subtask missing target_pose: {subtask}")
                return False

        elif action_type == 'manipulation':
            # Validate manipulation parameters
            params = subtask.get('parameters', {})
            if 'target_object' not in params:
                rospy.logerr(f"Manipulation subtask missing target_object: {subtask}")
                return False

        return True

    def execute_plan(self, plan: Dict[str, Any]) -> bool:
        """
        Execute the cognitive plan by publishing ROS 2 actions
        """
        if not self.validate_plan(plan):
            rospy.logerr("Plan validation failed, not executing")
            return False

        rospy.loginfo(f"Executing plan: {plan['task']}")

        try:
            for i, subtask in enumerate(plan['subtasks']):
                rospy.loginfo(f"Executing subtask {i+1}/{len(plan['subtasks'])}: {subtask['description']}")

                success = self.execute_subtask(subtask)
                if not success:
                    rospy.logerr(f"Subtask execution failed: {subtask}")
                    return False

                # Add small delay between subtasks for safety
                rospy.sleep(0.5)

            rospy.loginfo("Plan executed successfully")
            return True

        except Exception as e:
            rospy.logerr(f"Error executing plan: {str(e)}")
            return False

    def execute_subtask(self, subtask: Dict[str, Any]) -> bool:
        """
        Execute individual subtask based on action type
        """
        action_type = subtask['action_type']
        params = subtask.get('parameters', {})

        if action_type == 'navigation':
            return self.execute_navigation(params)
        elif action_type == 'manipulation':
            return self.execute_manipulation(params)
        elif action_type == 'perception':
            return self.execute_perception(params)
        else:
            rospy.logerr(f"Unknown action type: {action_type}")
            return False

    def execute_navigation(self, params: Dict[str, Any]) -> bool:
        """
        Execute navigation action
        """
        try:
            target_pose = params.get('target_pose')
            if target_pose is None:
                rospy.logerr("Navigation action missing target_pose")
                return False

            # Publish navigation goal
            pose_msg = Pose()
            pose_msg.position.x = target_pose.get('x', 0.0)
            pose_msg.position.y = target_pose.get('y', 0.0)
            pose_msg.position.z = target_pose.get('z', 0.0)

            # Set orientation if provided
            if 'orientation' in target_pose:
                orientation = target_pose['orientation']
                pose_msg.orientation.x = orientation.get('x', 0.0)
                pose_msg.orientation.y = orientation.get('y', 0.0)
                pose_msg.orientation.z = orientation.get('z', 0.0)
                pose_msg.orientation.w = orientation.get('w', 1.0)

            self.navigation_pub.publish(pose_msg)
            rospy.loginfo(f"Published navigation goal: {pose_msg}")
            return True

        except Exception as e:
            rospy.logerr(f"Error executing navigation: {str(e)}")
            return False

    def execute_manipulation(self, params: Dict[str, Any]) -> bool:
        """
        Execute manipulation action
        """
        try:
            target_object = params.get('target_object')
            if target_object is None:
                rospy.logerr("Manipulation action missing target_object")
                return False

            # Create manipulation command string
            action_msg = String()
            action_msg.data = f"manipulate:{target_object}"

            self.manipulation_pub.publish(action_msg)
            rospy.loginfo(f"Published manipulation command: {action_msg.data}")
            return True

        except Exception as e:
            rospy.logerr(f"Error executing manipulation: {str(e)}")
            return False

    def execute_perception(self, params: Dict[str, Any]) -> bool:
        """
        Execute perception action
        """
        try:
            perception_type = params.get('perception_type', 'detect')
            target_object = params.get('target_object')

            action_msg = String()
            if target_object:
                action_msg.data = f"{perception_type}:{target_object}"
            else:
                action_msg.data = f"{perception_type}:environment"

            self.perception_pub.publish(action_msg)
            rospy.loginfo(f"Published perception command: {action_msg.data}")
            return True

        except Exception as e:
            rospy.logerr(f"Error executing perception: {str(e)}")
            return False

# Example usage
if __name__ == '__main__':
    try:
        planner = CognitivePlanningNode()

        # Example command
        command = "Go to the kitchen and bring me the red apple from the counter"
        plan = planner.generate_plan(command)

        rospy.loginfo(f"Generated plan: {plan}")

        # In a real implementation, you would execute the plan
        # success = planner.execute_plan(plan)

        rospy.spin()
    except rospy.ROSInterruptException:
        pass
```

## Action Sequence Generation

The generation of action sequences from natural language requires careful consideration of task decomposition and sequencing:

### Task Decomposition Strategies

1. **Hierarchical Decomposition**: Break tasks into high-level goals, then subgoals
2. **Functional Decomposition**: Group actions by function (navigation, manipulation, etc.)
3. **Temporal Decomposition**: Order actions by time dependencies
4. **Spatial Decomposition**: Organize actions by location or area

### Safety Validation for Action Plans

Safety validation is critical for ensuring that planned actions don't cause harm:

- **Physical Safety**: Verify actions won't cause robot or environment damage
- **Operational Safety**: Check that actions are within robot capabilities
- **Context Safety**: Ensure actions are appropriate for current situation
- **Goal Safety**: Confirm actions align with overall task objective

## LLM Planning Flowchart

```
┌─────────────────────────────────────────────────────────────┐
│              LLM Cognitive Planning Flow                    │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────────────────────────────────────────┐   │
│  │            Natural Language Input                     │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │   │
│  │  │ Command     │ │ Context     │ │ Constraints │   │   │
│  │  │             │ │             │ │             │   │   │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │   │
│  └─────────────────────────────────────────────────────┘   │
│                             │                              │
│  ┌─────────────────────────────────────────────────────┐   │
│  │            LLM Processing                             │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │   │
│  │  │ Understanding│ │ Reasoning   │ │ Planning    │   │   │
│  │  │             │ │             │ │             │   │   │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │   │
│  └─────────────────────────────────────────────────────┘   │
│                             │                              │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           Plan Generation                             │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │   │
│  │  │ Task        │ │ Action      │ │ Safety      │   │   │
│  │  │ Breakdown   │ │ Sequencing  │ │ Validation  │   │   │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │   │
│  └─────────────────────────────────────────────────────┘   │
│                             │                              │
│  ┌─────────────────────────────────────────────────────┐   │
│  │          ROS 2 Action Execution                       │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │   │
│  │  │ Navigation  │ │ Manipulation│ │ Perception  │   │   │
│  │  │             │ │             │ │             │   │   │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │   │
│  └─────────────────────────────────────────────────────┘   │
│                             │                              │
│  ┌─────────────────────────────────────────────────────┐   │
│  │           Feedback & Monitoring                         │   │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐   │   │
│  │  │ Success     │ │ Error       │ │ Adaptation  │   │   │
│  │  │ Reporting   │ │ Handling    │ │             │   │   │
│  │  └─────────────┘ └─────────────┘ └─────────────┘   │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

## Example Pseudo-Code for LLM Planning

```python
# High-level pseudo-code for LLM-based cognitive planning

def cognitive_planning_pipeline(natural_language_command, robot_state, environment_context):
    """
    Main pipeline for cognitive planning with LLMs
    """
    # Step 1: Analyze the command with LLM
    task_analysis = analyze_command_with_llm(natural_language_command, environment_context)

    # Step 2: Decompose task into subtasks
    subtasks = decompose_task(task_analysis)

    # Step 3: Generate action sequence
    action_sequence = generate_action_sequence(subtasks, robot_state)

    # Step 4: Validate the plan for safety
    validated_plan = validate_plan_for_safety(action_sequence, environment_context)

    # Step 5: Optimize the plan for efficiency
    optimized_plan = optimize_plan(validated_plan)

    # Step 6: Execute the plan
    execution_result = execute_plan(optimized_plan)

    # Step 7: Monitor and adapt
    monitor_and_adapt(execution_result, environment_context)

    return execution_result

def analyze_command_with_llm(command, context):
    """
    Use LLM to understand the command and required capabilities
    """
    prompt = f"""
    Analyze this robot command: "{command}"

    Context: {context}

    Break down the command into:
    1. Main objective
    2. Required capabilities (navigation, manipulation, perception)
    3. Expected objects and locations
    4. Potential challenges
    """

    response = llm_query(prompt)
    return parse_task_analysis(response)

def generate_action_sequence(subtasks, robot_state):
    """
    Convert subtasks into executable ROS 2 actions
    """
    action_sequence = []

    for subtask in subtasks:
        action = convert_subtask_to_action(subtask, robot_state)
        if action:
            action_sequence.append(action)

    return action_sequence

def validate_plan_for_safety(plan, context):
    """
    Validate the plan for safety and feasibility
    """
    for action in plan:
        if not is_action_safe(action, context):
            raise SafetyValidationError(f"Action not safe: {action}")

    return plan
```

## Summary and Key Takeaways

Cognitive planning with LLMs provides the intelligent decision-making layer that transforms natural language commands into executable robotic actions. Key takeaways include:

- LLMs enable sophisticated natural language understanding for complex robotic tasks
- Proper prompt engineering is essential for reliable planning outcomes
- Safety validation is critical for ensuring plan feasibility and safety
- Task decomposition helps break complex commands into manageable actions
- Context awareness allows for adaptive planning based on environmental conditions
- The planning process must account for robot capabilities and limitations
- Feedback and monitoring enable plan adaptation during execution

The integration of LLM-based cognitive planning with robotic systems creates intelligent agents capable of understanding and executing complex, natural language commands.

## Key Terms Glossary

- **Cognitive Plan**: Sequence of robotic actions generated by LLM based on natural language understanding
- **LLM (Large Language Model)**: Advanced AI model capable of understanding and generating human language
- **Prompt Engineering**: Crafting effective prompts to guide LLM behavior for specific tasks
- **Action Sequence**: Ordered list of ROS 2 actions that accomplish a complex task
- **Task Decomposition**: Breaking down complex commands into simpler, executable actions
- **Chain-of-Thought**: Step-by-step reasoning approach for complex planning
- **Safety Validation**: Process of ensuring planned actions are safe and feasible
- **Context Window**: Limited memory of the LLM that affects planning complexity
- **Plan Dependencies**: Order relationships between actions in a sequence
- **Environmental Context**: Information about the robot's surroundings and capabilities

## Exercises and Practical Activities

1. **Prompt Engineering**: Experiment with different prompt formats for cognitive planning
2. **Plan Validation**: Implement safety validation checks for generated action sequences
3. **Task Decomposition**: Practice breaking down complex commands into subtasks
4. **LLM Comparison**: Test different LLMs for planning accuracy and reliability

## Further Reading and Resources

- [OpenAI API Documentation](https://platform.openai.com/docs/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Cognitive Robotics Research](https://ieeexplore.ieee.org/document/9149031)
- [Robot Planning Algorithms](https://motion.cs.umn.edu/papers/ijrr2018.pdf)

## See Also

- [Chapter 1: Voice-to-Action with Whisper](./chap-1-voice-to-action.md) - Learn about voice recognition and action mapping
- [Chapter 3: Capstone - Autonomous Humanoid](./chap-3-capstone.md) - Explore end-to-end VLA integration

## Navigation Links

[Previous: Chapter 1 - Voice-to-Action with Whisper](./chap-1-voice-to-action.md) | [Next: Chapter 3 - Capstone - Autonomous Humanoid](./chap-3-capstone.md)